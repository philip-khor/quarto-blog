---
title: Gradient boosting?
author: Philip Khor
date: '2022-04-20'
slug: gradient-boosting
categories: []
tags: []
subtitle: ''
summary: 'Yet another article trying to explain how GBMs work.'
authors: []
lastmod: '2022-04-20T08:57:37+08:00'
featured: no
commentable: yes
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---



<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>There’s no shortage of machine learning hot takes on how the XGBoost gradient boosting framework continues to defy the <a href="https://machinelearningmastery.com/no-free-lunch-theorem-for-machine-learning/">no-free-lunch theorem</a> by being perhaps the most versatile learning algorithm across tabular data applications.</p>
<p>Gradient boosting (GBM) packages such as XGBoost sequentially train a series of <strong>shallow</strong> trees, resulting in an <strong>ensemble</strong> model. In other words,</p>
<blockquote>
<p>GBMs start with a single question, then add one question at a time. Training stops when adding another question would make the model too complex to explain or wouldn’t improve its performance.</p>
<p>(paraphrased from <a href="https://blogs.nvidia.com/blog/2020/09/23/ai-credit-risk-scotiabank/">NVIDIA press release</a>).</p>
</blockquote>
<p>A final GBM model is the sum of <span class="math inline">\(B\)</span> individual trees (‘learners’), trained up to the point of diminishing returns<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<p><span class="math display">\[
F(x)=\sum^B_{b=1}f_b\left(x\right)
\]</span></p>
<p>This puts GBM squarely in the family of additive models<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> such as generalized additive models. GBMs sequentially nudge an initial weak model towards a strong model by consecutively <strong>adding</strong> simple models to an ensemble.</p>
<p>A gradient boosting model is:</p>
<ul>
<li><p><strong>trained using gradient descent</strong>. Similar to neural networks, the GBM learning algorithm optimizes the model sequentially using a gradient descent formulation. However, instead of optimizing individual model parameters, the GBM algorithm directly optimizes the model itself. This is sometimes known as <strong>gradient descent in functional space</strong>.</p></li>
<li><p><strong>a boosting model</strong>. In contrast with bagging learning algorithms such as random forests, boosting models take a different approach to model ensembling that uses simpler learners within an ensemble.</p>
<ul>
<li><p><strong>Bagging</strong> combines the wisdom of many individual learners to reduce variance (‘overfitting’). Resampling techniques ensure each tree in the ensemble is built differently. Learners in bagging ensembles are intentionally grown deep.</p></li>
<li><p><strong>Boosting</strong> combines weaker learners (‘models’) to form a strong overall model by sequentially improving (‘boosting’) the model’s performance using newer learners. This reduces model bias.</p></li>
</ul></li>
</ul>
</div>
<div id="learning-algorithm" class="section level2">
<h2>Learning algorithm</h2>
<p>Training a GBM begins with initializing a simple model <span class="math inline">\(f_0\)</span>, so that the model at iteration 0 is:</p>
<p><span class="math display">\[F_0(
\textbf{x}
)=f_0(\textbf{x})\]</span></p>
<p>where <span class="math inline">\(\textbf{x}\)</span> denotes the feature input vector. <span class="math inline">\(f_0\)</span> may be as simple as the average prediction. For a GBM modelling a single feature, the model may start off looking something like this<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a>:</p>
<p><img src="images/index.png" /></p>
<p>The idea behind gradient boosting is to adjust the model sequentially to ‘fix’ the errors.</p>
<ul>
<li>Where the actual values are above <span class="math inline">\(F_0\)</span>, the model should be adjusted <strong>upwards</strong>;</li>
<li>Where the actual values are below <span class="math inline">\(F_0\)</span>, the model should be adjusted <strong>downwards</strong>;</li>
</ul>
<p>The boosting approach to solving this problem is to fit a model to the errors <span class="math inline">\(\epsilon = y-F(\textbf{x})\)</span> at every iteration. At every iteration, we add a model of the errors to fix the previous model’s mistakes.</p>
<p><img src="images/index3.png" /></p>
<p>Stated differently, the model at the first boosting stage is the sum of the initial model <span class="math inline">\(F_0\)</span> and the model of the residuals <span class="math inline">\(f_1\)</span>:</p>
<p><span class="math display">\[F_1(\textbf{x})=F_0(\textbf{x})+f_1(\textbf{x})\]</span>Intuitively, the residuals <span class="math inline">\(\epsilon\)</span> indicate the <strong>direction</strong> in which the overall model should be nudged to get to the target value.</p>
<div id="gradient-descent" class="section level3">
<h3>Gradient descent?</h3>
<p>In practice, the residuals used to fit the learners are computed using the gradient of the loss function, and are also known as <strong>pseudoresiduals</strong>.</p>
<p>If we were to add the entirety of the model of the residuals <span class="math inline">\(f_1\)</span>:</p>
<p><span class="math display">\[F_1(\textbf{x})=F_0(\textbf{x})+f_1(\textbf{x})\]</span></p>
<p>then it may not be necessary to train for further iterations, since <span class="math inline">\(y=F_0(\textbf{x})+\epsilon\)</span><a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a>. So we slow down training by adding only a fraction <span class="math inline">\(\eta\)</span> of the learner:</p>
<p><span class="math display">\[F_1(\textbf{x})=F_0(\textbf{x})+\eta f_1(\textbf{x})\]</span></p>
<p><span class="math inline">\(\eta\)</span> is known as the learning rate. It’s also known as a shrinkage parameter, since it shrinks the contribution of each learner to the ensemble.</p>
<p>Or more generally, for the <span class="math inline">\(b\)</span>-th iteration:</p>
<p><span class="math display">\[F_b(\textbf{x})=F_{b-1}(\textbf{x})+\eta f_b(\textbf{x})\]</span></p>
<p>Notice how this parallels with gradient descent for neural networks, where the direction of adjustment for the <span class="math inline">\(j\)</span>-th <strong>model parameter</strong> <span class="math inline">\(\theta_j\)</span> is guided by the sign of the gradient:</p>
<p><span class="math display">\[\theta_{j} =\theta_{j}-\eta \frac{\delta}{\delta\theta_j}J(\theta)\]</span></p>
<p>where <span class="math inline">\(J(\theta)\)</span> refers to the loss function.</p>
<p>With gradient boosting, the direction of the gradient is used to adjust the <strong>overall model</strong> directly instead of individual model parameters.</p>
</div>
<div id="how-many-trees-then" class="section level3">
<h3>How many trees, then?</h3>
<p>It follows that lowering the learning rate <span class="math inline">\(\eta\)</span> generally requires more learners to build an optimal model. By slowing the speed of adjustment, the learning algorithm is more likely to converge, but a large ensemble may be required for an optimal model<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a>.</p>
<p>An approach to determining the number of learners required is known as <strong>early stopping</strong>. Additional learners are added until the point of diminishing returns, where there is no noticeable performance gain for adding new trees.</p>
<p>Since the model is trained iteratively, it is possible to score the model at every iteration. The <a href="https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.train"><code>early_stopping_rounds</code></a> argument in XGBoost checks the previous <code>early_stopping_rounds</code> for any improvement in the test score and trains the model for additional rounds only if improvements are observed.</p>
<p>Make sure to use separate sets of data for determining early stopping rounds and evaluating models.</p>
</div>
</div>
<div id="hyperparameters" class="section level2">
<h2>Hyperparameters</h2>
<p>A major challenge with tuning GBM models is knowing where to start from the large number of hyperparameters available. A great reference is <a href="https://sites.google.com/view/lauraepp/parameters">this table from Laurae++</a> which lists the mapping between hyperparameters in XGBoost and LightGBM.</p>
<p>Apart from learning rate and the number of trees, I group XGBoost hyperparameters into three categories:</p>
<table>
<caption>Categories of GBM hyperparameters</caption>
<colgroup>
<col width="68%" />
<col width="31%" />
</colgroup>
<thead>
<tr class="header">
<th>Categories</th>
<th>Hyperparameters</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><p><strong>Explicit regularization</strong></p>
<p>Directly adding cost for model complexity into the objective function</p></td>
<td>L1 (alpha) and L2 (lambda) regularization</td>
</tr>
<tr class="even">
<td><p><strong>Tree growth</strong></p>
<p>Control tree growth. I refer to some of these (maximum + pruning) as implicit regularization hyperparameters.</p></td>
<td><ul>
<li>Tree building method: “auto”, “exact”, “hist”</li>
<li>Tree growth method: “depthwise”, “lossguide”</li>
<li>Maximum depth, maximum leaves</li>
<li>Pruning: gamma, min_child_weight</li>
</ul></td>
</tr>
<tr class="odd">
<td><p><strong>Sampling</strong></p>
<p>Inspired by bagging/random forests</p></td>
<td>Row-wise and column-wise sampling</td>
</tr>
</tbody>
</table>
<p>For hyperparameter tuning, Optuna offers integration with <a href="https://github.com/optuna/optuna-examples/tree/main/xgboost/xgboost_integration.py">XGBoost</a>, <a href="https://github.com/optuna/optuna-examples/tree/main/catboost/catboost_pruning.py">Catboost</a> and <a href="https://github.com/optuna/optuna-examples/tree/main/lightgbm/lightgbm_integration.py">LightGBM</a> to incorporate early stopping.</p>
</div>
<div id="implementations" class="section level2">
<h2>Implementations</h2>
<p>There’s at least 4 major implementations of GBMs:</p>
<ul>
<li>XGBoost</li>
<li>LightGBM</li>
<li>Catboost</li>
<li>sklearn.ensemble.HistGradientBoosting*</li>
</ul>
<p>There’s no shortage of articles comparing these different implementations.</p>
<p>These libraries (in particular XGBoost and LightGBM) do borrow ideas from each other. For instance, I list down the major differences between XGBoost and LightGBM below, however these LightGBM features are also available in XGBoost as options:</p>
<table>
<colgroup>
<col width="12%" />
<col width="30%" />
<col width="57%" />
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>XGBoost</th>
<th>LightGBM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tree building method</td>
<td>Exact: enumerate all split candidates</td>
<td>Features are discretized/binned beforehand (<a href="https://robotenique.github.io/posts/gbm-histogram/">hist</a>)</td>
</tr>
<tr class="even">
<td>Tree growth method</td>
<td>Depthwise/level-wise: trees are grown level by level.</td>
<td>Lossguide/leaf-wise: split based on best global loss</td>
</tr>
</tbody>
</table>
</div>
<div id="building-interpretable-gbms" class="section level2">
<h2>Building interpretable GBMs</h2>
<p>In some applications, it is necessary to consider additional measures to ensure the trustworthiness of a model.</p>
<div id="monotonic-constraints" class="section level3">
<h3>Monotonic constraints</h3>
<p>It may be useful to ensure that a GBM is constructed to align with certain ex ante expectations of how a feature is related to the target variable. Monotonic constraints ensure that a specified relationship is either strictly increasing or decreasing. See <a href="https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html" class="uri">https://xgboost.readthedocs.io/en/stable/tutorials/monotonic.html</a> for details.</p>
</div>
<div id="feature-interaction-constraints" class="section level3">
<h3>Feature interaction constraints</h3>
<p>In tree-based models, each additional level introduces interactions to the model. Interactions are where combinations of feature values matter to the model, and not just individual feature values. The additive structure of GBMs makes it possible to restrict interactions captured in a model by limiting the features used in each iteration.</p>
<ol style="list-style-type: decimal">
<li><a href="https://interpret.ml/docs/ebm.html">Explainable Boosting Machines</a> train on one feature at a time and incorporate automatic detection of interactions, such that the resulting model can be directly interpreted by summing up across all trees.</li>
<li><a href="https://xgboost.readthedocs.io/en/stable/tutorials/feature_interaction_constraint.html">XGBoost</a> allows users to specify which feature interactions are permitted. As an example, Scotiabank <a href="https://colab.research.google.com/github/wandb/examples/blob/master/colabs/boosting/Credit_Scorecards_with_XGBoost_and_W%26B.ipynb">transforms XGBoost models</a> trained with feature interaction constraints into a scorecard format for use in credit assessment.</li>
</ol>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>adapted from <a href="https://bradleyboehmke.github.io/HOML/gbm.html" class="uri">https://bradleyboehmke.github.io/HOML/gbm.html</a><a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p><a href="https://explained.ai/gradient-boosting/L2-loss.html" class="uri">https://explained.ai/gradient-boosting/L2-loss.html</a><a href="#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>Visualizations from <a href="https://github.com/madrury/boosting-presentation/blob/master/Boosting-Presentation-Galvanize.ipynb" class="uri">https://github.com/madrury/boosting-presentation/blob/master/Boosting-Presentation-Galvanize.ipynb</a><a href="#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>Additionally, <span class="math inline">\(\eta=1\)</span> may result in the error function spiralling about the minimum like so: <a href="https://stats.stackexchange.com/questions/282544/why-does-reducing-the-learning-rate-quickly-reduce-the-error/282555#282555" class="uri">https://stats.stackexchange.com/questions/282544/why-does-reducing-the-learning-rate-quickly-reduce-the-error/282555#282555</a><a href="#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>This should not be taken as an indication of overfitting: the observation of double descent in neural networks suggests that extremely complex models do not necessarily overfit. However, limiting model complexity may be desirable for other reasons e.g. interpretability.<a href="#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>

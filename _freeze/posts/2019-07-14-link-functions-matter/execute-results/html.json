{
  "hash": "a38dfff2827c36b7605efcb7260cffe3",
  "result": {
    "markdown": "---\ntitle: Link functions matter\nauthor: \"Philip Khor\"\ndate: '2019-07-14'\nslug: link-functions-matter\ncategories: []\ntags: []\nsubtitle: ''\nsummary: 'Benchmarking different link functions'\nauthors: []\nlastmod: '2019-07-14T10:50:34+09:00'\nfeatured: no\nprojects: []\n---\n\n\nThere's a bit of a conversation on Twitter whether to use linear models or logistic models for estimating effect sizes in the case of binary response variables. I wondered if linear models can work for prediction problems with binary response variables, since there may be cases where the latent probability is linearly related to the features.\n\nSo I thought I'd do a little benchmark between different link functions for regression-based classifiers for the Titanic problem, based on the `tidymodels` packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vroom)\nlibrary(here)\nlibrary(janitor)\nlibrary(dplyr)\nlibrary(rsample)\nlibrary(recipes)  \nlibrary(stringr)\nlibrary(broom) \nlibrary(magrittr)\nlibrary(yardstick)\nlibrary(tibble)\n\nvroom(here(\"static\", \"data\", \"train.csv\")) %>% \n  clean_names() -> titanic_train\nvroom(here(\"static\", \"data\", \"train.csv\")) %>% \n  clean_names() -> titanic_testing\n```\n:::\n\n\nPreprocessing steps are taken from Megan Risdal's R kernel on Kaggle, [Exploring the Titanic Dataset](https://www.kaggle.com/mrisdal/exploring-survival-on-the-titanic), with the major change being that I use bagging imputation instead of MICE imputation for the Age column.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecipe(titanic_train) %>% \n  step_mutate(survived = survived, role = \"outcome\") %>% \n  update_role(pclass, age, sib_sp, parch, fare, \n              new_role = \"predictor\") %>% \n  step_mutate(embarked = as.factor(embarked), \n         sex = as.factor(sex), \n         fsize = parch + sib_sp + 1, \n         title = gsub('(.*,)|\\\\s|(\\\\..*)', \"\", name),\n         title = str_trim(title), \n         fsize_d = case_when(\n           fsize == 1 ~ \"singleton\", \n           fsize < 5 & fsize > 1 ~ \"small\",\n           fsize > 4 ~ \"large\"\n         ), \n         role = \"predictor\") %>% \n  step_impute_bag(age, \n                 impute_with = imp_vars(-passenger_id, \n                                        -name, \n                                        -ticket,\n                                        -cabin,\n                                        -survived)) %>% \n  step_unknown(title) %>% \n  step_mutate(title = ifelse(is.na(title), \"unknown\", title)) %>% \n  step_mutate(child = as.factor(age < 18),\n              mother = sex == \"female\" & parch > 0 & age > 18 & title == \"Miss\", \n              role = \"predictor\")  %>% \n  step_other(title, threshold = .05) -> rec\n\ntrained_rec <- prep(rec, training = titanic_train)\ntitanic_training <- bake(trained_rec, new_data = titanic_train)\ntitanic_testing <- bake(trained_rec, new_data = titanic_testing)\n```\n:::\n\n\nI then fit linear and non-linear models:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nformula <- survived ~ pclass + sex + age + sib_sp + parch +\n     fare + embarked + as.factor(title) + fsize_d + child + mother\n     \nlm(formula, data = titanic_training) -> reg\n\nglm(formula, \n   data = titanic_training, family = \"binomial\") -> log_reg\n\nglm(formula, \n   data = titanic_training, \n   family = binomial(link = \"probit\")) -> prob_reg\n   \nglm(formula, \n   data = titanic_training, \n   family = binomial(link = \"cauchit\")) -> cauch_reg\n```\n:::\n\n\nThese classifiers all have a common theme - they use an underlying regression model to estimate probabilities. The weakness of using a linear model for classification problems is that the probabilities can be less than 0 or more than 1, which defies the rules of probability. [Len Kiefer](http://lenkiefer.com/2018/07/21/maybe-the-linear-probability-model-isn-t-all-bad/) explores **trimmed OLS** for estimating effect sizes, where we eliminate observations where the predicted probabilities are less than 0 or more than 1 first, then re-estimate OLS. The code for trimmed OLS are as follows:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# trimmed OLS\nreg %>% \n  augment() %>% \n  filter(.fitted < 0 | .fitted > 1) -> out_of_bounds\n\ntitanic_training %>% \n  rownames_to_column(var = '.rownames') %>% \n  anti_join(out_of_bounds, \n            by = \".rownames\") %$%\n  lm(formula, data = .) -> trimmed_ols\n```\n:::\n\n\nAnd now time to evaluate. While the OLS models don't perform as well here, the model using the Cauchit link function provides the highest accuracy score:\n\n\n::: {.cell}\n\n```{.r .cell-code}\neval <- function(model, newdata = titanic_testing, type.predict = NULL) {\n  multi_metric <- metric_set(accuracy, kap)\n  model %>% \n    augment(newdata = newdata, \n            type.predict = type.predict) %>% \n    mutate(pred_class = as.integer(.fitted > .5)) %>% \n    multi_metric(as.factor(survived), estimate = as.factor(pred_class))\n}\n\nbind_rows(list(eval(reg),\n               eval(trimmed_ols),\n               eval(log_reg, type.predict = \"response\"),\n               eval(prob_reg, type.predict = \"response\"),\n               eval(cauch_reg, type.predict = \"response\")\n               )) %>% \n  mutate(model = rep(c(\"OLS\", \"trimmed OLS\", \"logit\", \"probit\", \"cauchit\"), \n                     each = 2)) %>% \n  select(model, .metric, .estimator, .estimate) %>% \n  arrange(.metric, desc(.estimate))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(x, newdata = newdata, na.action = na.pass, ...):\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(x, newdata = newdata, na.action = na.pass, ...):\nprediction from a rank-deficient fit may be misleading\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n\nWarning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == :\nprediction from a rank-deficient fit may be misleading\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 Ã— 4\n   model       .metric  .estimator .estimate\n   <chr>       <chr>    <chr>          <dbl>\n 1 cauchit     accuracy binary         0.836\n 2 logit       accuracy binary         0.828\n 3 OLS         accuracy binary         0.827\n 4 trimmed OLS accuracy binary         0.827\n 5 probit      accuracy binary         0.827\n 6 cauchit     kap      binary         0.643\n 7 logit       kap      binary         0.633\n 8 probit      kap      binary         0.631\n 9 OLS         kap      binary         0.630\n10 trimmed OLS kap      binary         0.630\n```\n:::\n:::\n\n\nLooks like the cauchit model has the highest accuracy, and OLS isn't too far behind the logit. But why does the cauchit link function perform better?\n\n> The \"cauchit\" model is attractive when observed responses exhibit a few surprising values, observations for which the linear predictor is large in absolute value indicating that the outcome is almost certain, and yet the linear predictor is wrong. (http://www.econ.uiuc.edu/\\~roger/research/links/links.pdf)\n\nI'm having trouble braining this paragraph, but it sounds like the cauchit is robust to large values of the predictors. Is this the case? For simplicity I check the fitted values from the linear model:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nreg %>% \n  augment() %>% \n  ggplot(aes(x = .fitted)) + geom_histogram()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](2019-07-14-link-functions-matter_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\nSeems to be a few extreme cases, but not too harsh.\n",
    "supporting": [
      "2019-07-14-link-functions-matter_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}